{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Generic Machine Learning\" \n",
    "> \"Code for generic ML\" \n",
    "\n",
    "- toc:false\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Mun Fai Chan\n",
    "- categories: [fastpages, jupyter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "This notebook provides code to Generic Machine Learning Inference on Heterogenous Treatment Effects in Randomized Experiments by Victor Chernozhukov, Mert Demirer, Esther Duflo, and Iván Fernández-Val. \n",
    "\n",
    "https://arxiv.org/abs/1712.04802\n",
    "\n",
    "### References \n",
    "https://github.com/arnaudfrn/MLheterogeneity/blob/dev/src/vb_heterogeneity_FE.R\n",
    "\n",
    "Many thanks to Arnaud Fournier, who provided the R code for this.  \n",
    "\n",
    "Author of notebook : Mun Fai Chan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Future developments for code\n",
    "\n",
    "1. Hyperparemeter tuning on ML estimators\n",
    "2. Converting pandas dataframes to LaTex tables. \n",
    "3. Aesthetic updates - includes adding astericks for significance \n",
    "4. Add in fixed effects \n",
    "\n",
    "#### Other developments\n",
    "1. Empirical application\n",
    "2. Monte Carlo simulation to test veracity and robustness of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from propscore import PropensityScore\n",
    "import random\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "import numpy as np\n",
    "import statistics as stats\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalinference import CausalModel\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import svm\n",
    "from sklearn import datasets, ensemble\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"~/OneDrive - London School of Economics/LSE/Year 3/EC331/November/simdata1.csv\")\n",
    "# In this simulated dataset, all controls are uniformly random around (-1,1). Treatment (binary) is randomly assigned\n",
    "# and has a treatment effect of 2.0 + some gaussian noise. \n",
    "\n",
    "controls = ['X1','X2','X3','X4','X5']\n",
    "treatment = 'treatment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              treatment   No. Observations:                 2000\n",
      "Model:                          Logit   Df Residuals:                     1996\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Mon, 04 Jan 2021   Pseudo R-squ.:                0.003082\n",
      "Time:                        14:12:22   Log-Likelihood:                -1382.0\n",
      "converged:                       True   LL-Null:                       -1386.3\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.03598\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "X4             0.0656      0.044      1.481      0.138      -0.021       0.152\n",
      "X1XX2         -0.0862      0.046     -1.889      0.059      -0.176       0.003\n",
      "X4_sq          0.0576      0.032      1.802      0.072      -0.005       0.120\n",
      "_cons         -0.0592      0.056     -1.066      0.286      -0.168       0.050\n",
      "==============================================================================\n",
      "The following vars were infeasible: \n",
      "Stratification produced 4 strata\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>treatment</th>\n",
       "      <th>outcome</th>\n",
       "      <th>propscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.222325</td>\n",
       "      <td>1.096420</td>\n",
       "      <td>0.791501</td>\n",
       "      <td>-0.047723</td>\n",
       "      <td>-0.638967</td>\n",
       "      <td>1</td>\n",
       "      <td>1.896553</td>\n",
       "      <td>0.479204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.333924</td>\n",
       "      <td>-2.472571</td>\n",
       "      <td>-0.635518</td>\n",
       "      <td>0.640664</td>\n",
       "      <td>0.408980</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.005217</td>\n",
       "      <td>0.483821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.635914</td>\n",
       "      <td>-0.714505</td>\n",
       "      <td>0.170289</td>\n",
       "      <td>-0.591279</td>\n",
       "      <td>-0.211143</td>\n",
       "      <td>0</td>\n",
       "      <td>0.097441</td>\n",
       "      <td>0.470775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.618626</td>\n",
       "      <td>-1.055120</td>\n",
       "      <td>0.486168</td>\n",
       "      <td>-0.441626</td>\n",
       "      <td>-2.865479</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015330</td>\n",
       "      <td>0.494820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.807180</td>\n",
       "      <td>1.475266</td>\n",
       "      <td>-0.033577</td>\n",
       "      <td>0.354557</td>\n",
       "      <td>0.868843</td>\n",
       "      <td>1</td>\n",
       "      <td>1.893319</td>\n",
       "      <td>0.467209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X1        X2        X3        X4        X5  treatment   outcome  \\\n",
       "0  0.222325  1.096420  0.791501 -0.047723 -0.638967          1  1.896553   \n",
       "1 -0.333924 -2.472571 -0.635518  0.640664  0.408980          0 -0.005217   \n",
       "2 -0.635914 -0.714505  0.170289 -0.591279 -0.211143          0  0.097441   \n",
       "3  0.618626 -1.055120  0.486168 -0.441626 -2.865479          0  0.015330   \n",
       "4  0.807180  1.475266 -0.033577  0.354557  0.868843          1  1.893319   \n",
       "\n",
       "   propscore  \n",
       "0   0.479204  \n",
       "1   0.483821  \n",
       "2   0.470775  \n",
       "3   0.494820  \n",
       "4   0.467209  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = PropensityScore(treatment, controls, df);\n",
    "df = df.join(ps.propscore)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Initialisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 100\n",
    "k = 5 # number of groups for heterogeneity analysis\n",
    "alpha = 0.05 # significance level "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest: lamda1: -5.765410377113008e-05 lambda2: 0.7962556067959392\n",
      "SVM: lamda1: 6.37687223615527e-05 lambda2: 0.7990199258698686\n",
      "gradient_boost: lamda1: -5.810927679997994e-06 lambda2: 0.7972126884049128\n",
      "neural_net: lamda1: -0.00013872698846416478 lambda2: 0.7969536495255202\n",
      "ElasticNet: lamda1: 0.00038697229802813827 lambda2: 0.7977092031809006\n"
     ]
    }
   ],
   "source": [
    "ML_models = [\"random_forest\", \"SVM\", \"gradient_boost\", \"neural_net\", \"ElasticNet\"]\n",
    "\n",
    "for x in ML_models: \n",
    "    summary = Generic_ML_single(df, controls, 10, x, alpha , 5) \n",
    "    print (str(x) + \": lamda1: \" + str(summary[-2])+ \" lambda2: \" + str(summary[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows us to quickly compare between different ML estimators. In particular, we want to minimise lambda1 and lambda2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = Generic_ML_single(df, controls, iterations, \"random_forest\", alpha , 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ATE</th>\n",
       "      <th>HET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>coeff</td>\n",
       "      <td>2.002647</td>\n",
       "      <td>0.019719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>se</td>\n",
       "      <td>0.007427</td>\n",
       "      <td>0.074006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pvalue</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.987714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lower bound</td>\n",
       "      <td>1.987861</td>\n",
       "      <td>-0.120732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>upper bound</td>\n",
       "      <td>2.017433</td>\n",
       "      <td>0.162308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ATE       HET\n",
       "coeff        2.002647  0.019719\n",
       "se           0.007427  0.074006\n",
       "pvalue       0.000000  0.987714\n",
       "lower bound  1.987861 -0.120732\n",
       "upper bound  2.017433  0.162308"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLP = summary[0]; BLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>G1</th>\n",
       "      <th>G5</th>\n",
       "      <th>G1 - G5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>coeff</td>\n",
       "      <td>1.995021</td>\n",
       "      <td>2.010402</td>\n",
       "      <td>-0.012300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>se</td>\n",
       "      <td>0.017296</td>\n",
       "      <td>0.017322</td>\n",
       "      <td>0.024500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pvalue</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lower bound</td>\n",
       "      <td>1.960978</td>\n",
       "      <td>1.976616</td>\n",
       "      <td>-0.061299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>upper bound</td>\n",
       "      <td>2.029177</td>\n",
       "      <td>2.044189</td>\n",
       "      <td>0.036699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   G1        G5   G1 - G5\n",
       "coeff        1.995021  2.010402 -0.012300\n",
       "se           0.017296  0.017322  0.024500\n",
       "pvalue       0.000000  0.000000  1.000000\n",
       "lower bound  1.960978  1.976616 -0.061299\n",
       "upper bound  2.029177  2.044189  0.036699"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GATES = summary[1]; GATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coeff</th>\n",
       "      <th>se</th>\n",
       "      <th>pvalue</th>\n",
       "      <th>lower bound</th>\n",
       "      <th>upper bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Most affected X1</td>\n",
       "      <td>-0.046367</td>\n",
       "      <td>0.079034</td>\n",
       "      <td>0.393447</td>\n",
       "      <td>-0.202160</td>\n",
       "      <td>0.109426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Least affected X1</td>\n",
       "      <td>-0.025723</td>\n",
       "      <td>0.079034</td>\n",
       "      <td>0.456220</td>\n",
       "      <td>-0.181875</td>\n",
       "      <td>0.130428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Most - least affected X1</td>\n",
       "      <td>0.033200</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.693000</td>\n",
       "      <td>-0.460711</td>\n",
       "      <td>0.527111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Most affected X2</td>\n",
       "      <td>0.026326</td>\n",
       "      <td>0.083156</td>\n",
       "      <td>0.602332</td>\n",
       "      <td>-0.136445</td>\n",
       "      <td>0.189097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Least affected X2</td>\n",
       "      <td>-0.007814</td>\n",
       "      <td>0.083156</td>\n",
       "      <td>0.345540</td>\n",
       "      <td>-0.170585</td>\n",
       "      <td>0.154957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Most - least affected X2</td>\n",
       "      <td>0.034150</td>\n",
       "      <td>0.131500</td>\n",
       "      <td>0.620500</td>\n",
       "      <td>-0.222605</td>\n",
       "      <td>0.290905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Most affected X3</td>\n",
       "      <td>0.051797</td>\n",
       "      <td>0.081971</td>\n",
       "      <td>0.473087</td>\n",
       "      <td>-0.112999</td>\n",
       "      <td>0.216593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Least affected X3</td>\n",
       "      <td>-0.010720</td>\n",
       "      <td>0.081971</td>\n",
       "      <td>0.637616</td>\n",
       "      <td>-0.172631</td>\n",
       "      <td>0.151190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Most - least affected X3</td>\n",
       "      <td>0.049050</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.542000</td>\n",
       "      <td>-0.207705</td>\n",
       "      <td>0.305805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Most affected X4</td>\n",
       "      <td>0.015797</td>\n",
       "      <td>0.083432</td>\n",
       "      <td>0.578876</td>\n",
       "      <td>-0.147815</td>\n",
       "      <td>0.179409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Least affected X4</td>\n",
       "      <td>-0.031468</td>\n",
       "      <td>0.083432</td>\n",
       "      <td>0.494258</td>\n",
       "      <td>-0.197107</td>\n",
       "      <td>0.134171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Most - least affected X4</td>\n",
       "      <td>0.039350</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>0.532000</td>\n",
       "      <td>-0.213485</td>\n",
       "      <td>0.292185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Most affected X5</td>\n",
       "      <td>-0.008161</td>\n",
       "      <td>0.080664</td>\n",
       "      <td>0.324056</td>\n",
       "      <td>-0.166095</td>\n",
       "      <td>0.149773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Least affected X5</td>\n",
       "      <td>-0.012703</td>\n",
       "      <td>0.080664</td>\n",
       "      <td>0.338504</td>\n",
       "      <td>-0.171438</td>\n",
       "      <td>0.146032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Most - least affected X5</td>\n",
       "      <td>0.010450</td>\n",
       "      <td>0.127500</td>\n",
       "      <td>0.414000</td>\n",
       "      <td>-0.240425</td>\n",
       "      <td>0.261325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             coeff        se    pvalue  lower bound  \\\n",
       "Most affected X1         -0.046367  0.079034  0.393447    -0.202160   \n",
       "Least affected X1        -0.025723  0.079034  0.456220    -0.181875   \n",
       "Most - least affected X1  0.033200  0.250000  0.693000    -0.460711   \n",
       "Most affected X2          0.026326  0.083156  0.602332    -0.136445   \n",
       "Least affected X2        -0.007814  0.083156  0.345540    -0.170585   \n",
       "Most - least affected X2  0.034150  0.131500  0.620500    -0.222605   \n",
       "Most affected X3          0.051797  0.081971  0.473087    -0.112999   \n",
       "Least affected X3        -0.010720  0.081971  0.637616    -0.172631   \n",
       "Most - least affected X3  0.049050  0.130000  0.542000    -0.207705   \n",
       "Most affected X4          0.015797  0.083432  0.578876    -0.147815   \n",
       "Least affected X4        -0.031468  0.083432  0.494258    -0.197107   \n",
       "Most - least affected X4  0.039350  0.132000  0.532000    -0.213485   \n",
       "Most affected X5         -0.008161  0.080664  0.324056    -0.166095   \n",
       "Least affected X5        -0.012703  0.080664  0.338504    -0.171438   \n",
       "Most - least affected X5  0.010450  0.127500  0.414000    -0.240425   \n",
       "\n",
       "                          upper bound  \n",
       "Most affected X1             0.109426  \n",
       "Least affected X1            0.130428  \n",
       "Most - least affected X1     0.527111  \n",
       "Most affected X2             0.189097  \n",
       "Least affected X2            0.154957  \n",
       "Most - least affected X2     0.290905  \n",
       "Most affected X3             0.216593  \n",
       "Least affected X3            0.151190  \n",
       "Most - least affected X3     0.305805  \n",
       "Most affected X4             0.179409  \n",
       "Least affected X4            0.134171  \n",
       "Most - least affected X4     0.292185  \n",
       "Most affected X5             0.149773  \n",
       "Least affected X5            0.146032  \n",
       "Most - least affected X5     0.261325  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLAN = summary[2]; CLAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BLP(df, alpha): \n",
    "    '''\n",
    "    Returns summary results, whose parameters can be used to obtain BLP of CATE. \n",
    "    Contains: \n",
    "        Estimator Coefficients of Term 2 and 3 \n",
    "        Standard Error \n",
    "        p values \n",
    "        Confidence Interval (lower and upper bounds)\n",
    "    \n",
    "    Returns lambda1 - value to help choose the best ML method \n",
    "        \n",
    "    '''\n",
    "    \n",
    "    term2 = df['treatment'] - df['propscore']\n",
    "    S = df['S']\n",
    "    term3 = term2 * (S - np.mean(S))\n",
    "    \n",
    "    \n",
    "    combined = df.copy()\n",
    "    combined.loc[:,'term2'] = term2 \n",
    "    combined.loc[:,'term3'] = term3\n",
    "    combined.loc[:,'ones'] = 1 \n",
    "    \n",
    "    X_reg = combined[['B', 'S', 'ones', 'term2', 'term3']]\n",
    "    y = combined[['outcome']]\n",
    "    \n",
    "    regBLP = sm.OLS(y, X_reg)\n",
    "    res_BLP = regBLP.fit()\n",
    "    \n",
    "    res_BLP = results_summary_to_dataframe(res_BLP, alpha)\n",
    "    \n",
    "    lambda1 = res_BLP.iloc[-1,0] * stats.variance(S)   \n",
    "    return res_BLP, lambda1\n",
    "    \n",
    "def results_summary_to_dataframe(results, alpha):\n",
    "    '''take the result of an statsmodel results table and transforms it into a dataframe'''\n",
    "    pvals = results.pvalues\n",
    "    coeff = results.params\n",
    "    std_err = results.bse\n",
    "    \n",
    "    crit_val = norm.ppf(1-alpha/2) \n",
    "\n",
    "    lb = coeff - std_err * crit_val\n",
    "    ub = coeff + std_err * crit_val\n",
    "    \n",
    "\n",
    "    results_df = pd.DataFrame({\"pvals\":pvals,\n",
    "                               \"coeff\":coeff,\n",
    "                               \"lb\":lb,\n",
    "                               \"ub\":ub,\n",
    "                               \"std_err\":std_err, \n",
    "                                })\n",
    "\n",
    "    #Reordering...\n",
    "    results_df = results_df[[\"coeff\",\"std_err\",\"pvals\",\"lb\",\"ub\"]]\n",
    "    return results_df\n",
    "\n",
    "def BLP_to_storage(res_BLP):\n",
    "    \n",
    "    '''\n",
    "    Takes the output of BLP and store them as lists, whereby the output refers to: \n",
    "        res_BLP - summary table containing parameters to construct BLP, along with their p-values, standard errors and lower and upper bounds\n",
    "        \n",
    "    Returns 2 lists data_HET and data_ATE whose array-equivalent is of dimension (1 variable, 5 attributes)\n",
    "    '''\n",
    "    \n",
    "    # HET parameter \n",
    "    HET = res_BLP.iloc[-1,0]\n",
    "    HET_se = res_BLP.iloc[-1,1]\n",
    "    HET_pvals = res_BLP.iloc[-1, 2]\n",
    "    HET_lb = res_BLP.iloc[-1, 3]\n",
    "    HET_ub = res_BLP.iloc[-1, 4]\n",
    "\n",
    "    # ATE \n",
    "    ATE = res_BLP.iloc[-2,0]\n",
    "    ATE_se = res_BLP.iloc[-2,1]\n",
    "    ATE_pvals = res_BLP.iloc[-2,2]\n",
    "    ATE_lb = res_BLP.iloc[-2,3]\n",
    "    ATE_ub = res_BLP.iloc[-2,4]\n",
    "    \n",
    "    # Storage\n",
    "    \n",
    "    data_HET = [HET, HET_se, HET_pvals, HET_lb, HET_ub]\n",
    "    data_ATE = [ATE, ATE_se, ATE_pvals, ATE_lb, ATE_ub]\n",
    "\n",
    "    return data_HET, data_ATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GATES(df, k , alpha): \n",
    "    '''\n",
    "    Returns summary statistics, whose results can give us the average treatment effect \n",
    "    for most and least affected group. \n",
    "    \n",
    "    Contains: \n",
    "        Estimator Coefficients  \n",
    "        Standard Error \n",
    "        p values \n",
    "        Confidence Interval (lower and upper bounds)\n",
    "        \n",
    "    Returns lambda2 - value to help choose the best ML method \n",
    "    \n",
    "    Parameters \n",
    "    ----------\n",
    "    df -- (main) dataframe which must contain the following items: \n",
    "        propensity score \n",
    "        B - proxy predictor for BCA \n",
    "        S - proxy predictor for CATE\n",
    "        treatment \n",
    "        \n",
    "    k -- number of groups \n",
    "    '''\n",
    "    \n",
    "    combined = df.copy()\n",
    "    term2 = df['treatment'] - df['propscore']\n",
    "    combined.loc[:,'term2'] = term2\n",
    "    combined.loc[:,'ones'] = 1\n",
    "    \n",
    "    groups = groups_multiply(df, group_create(k, df), k)\n",
    "    combined = pd.concat([combined,groups], axis = 1) \n",
    "  \n",
    "    controls = [\"B\", \"S\", \"ones\"] + [\"G\" + str(i) for i in range(1,k+1)]\n",
    "    X_GATES = combined[controls] # modify for auto selection of columns\n",
    "    y = combined[['outcome']]\n",
    "    \n",
    "    regGATES = sm.OLS(y, X_GATES)\n",
    "    res_GATES = regGATES.fit()\n",
    "    \n",
    "    # Hypothesis testing \n",
    "    hypothesis = \"(G1 = \" + \"G\" + str(k) + \")\" # G1 = G{k}\n",
    "    t_test_html = res_GATES.t_test(hypothesis).summary().as_html()\n",
    "    t_test = pd.read_html(t_test_html, header=0, index_col=0)[0]\n",
    "    \n",
    "    res_GATES = results_summary_to_dataframe(res_GATES, alpha)\n",
    "    \n",
    "    lambda2 = res_GATES.iloc[3:, 0].mean()**2 / k\n",
    "    \n",
    "    return res_GATES, t_test, lambda2\n",
    "    \n",
    "\n",
    "def group_create(k, df): \n",
    "    '''\n",
    "    Returns quantiles of the variable 'S', encoded into dummy variables\n",
    "    '''\n",
    "    breaks = df['S'].quantile(np.linspace(0,1,(k+1)))\n",
    "    breaks.iloc[0,] = breaks.iloc[0,] - 0.001 \n",
    "    breaks.iloc[k,] = breaks.iloc[k,] - 0.001 \n",
    "    \n",
    "    combined = df.copy()\n",
    "    combined['Groups'] = pd.cut(x= df['S'], bins = breaks) # this will fail if there are too many groups\n",
    "    groups = pd.get_dummies(combined['Groups'])\n",
    "    \n",
    "    return groups\n",
    "\n",
    "def groups_multiply(df, groups, k):\n",
    "    '''\n",
    "    Multiply groups dataframe with term 2 and rename columns \n",
    "    '''\n",
    "    \n",
    "    combined = df.copy()\n",
    "    term2 = df['treatment'] - df['propscore']\n",
    "    combined.loc[:,'term2'] = term2\n",
    "    \n",
    "    groups = np.multiply(groups, combined['term2'].values.reshape(len(df.index),1))\n",
    "    groups.columns = [\"G\" + str(i) for i in range(1,k+1)] \n",
    "    \n",
    "    return groups\n",
    "\n",
    "def GATES_to_storage(res_GATES, t_test_GATES, alpha):\n",
    "    \n",
    "    '''\n",
    "    Takes the output of GATES and store them as lists, whereby the output refers to: \n",
    "        res_GATES - summary table containing parameters to construct GATES, along with their p-values and standard errors \n",
    "        t_test_GATEs - t test table to determine if G1 = Gk \n",
    "    \n",
    "    Returns a list whose array-equivalent is dimension of (# of variables, # of attributes )\n",
    "    '''\n",
    "    \n",
    "    # Most affected group \n",
    "    gamma1 = res_GATES.iloc[3,0]\n",
    "    gamma1_se = res_GATES.iloc[3,1]\n",
    "    gamma1_pvals = res_GATES.iloc[3,2]\n",
    "    gamma1_lb = res_GATES.iloc[3,3]\n",
    "    gamma1_ub = res_GATES.iloc[3,4]\n",
    "\n",
    "    # Least affected group \n",
    "    gammak = res_GATES.iloc[-1,0]\n",
    "    gammak_se = res_GATES.iloc[-1,1]\n",
    "    gammak_pvals = res_GATES.iloc[-1,2]\n",
    "    gammak_lb = res_GATES.iloc[-1,3]\n",
    "    gammak_ub = res_GATES.iloc[-1,4]\n",
    "    \n",
    "    # Difference between most and least affected group \n",
    "  \n",
    "    crit_val = norm.ppf(1-alpha/2) \n",
    "\n",
    "    gamma_diff = t_test_GATES.iloc[0,0]\n",
    "    gamma_diff_se = t_test_GATES.iloc[0,1]\n",
    "    gamma_diff_pvals = t_test_GATES.iloc[0,3] \n",
    "    gamma_diff_lb = gamma_diff - crit_val * gamma_diff_se\n",
    "    gamma_diff_ub = gamma_diff + crit_val * gamma_diff_se\n",
    "    \n",
    "    data_gamma1 = [gamma1, gamma1_se, gamma1_pvals, gamma1_lb, gamma1_ub]\n",
    "    data_gammak = [gammak, gammak_se, gammak_pvals, gammak_lb, gammak_ub]\n",
    "    data_gamma_diff = [gamma_diff, gamma_diff_se, gamma_diff_pvals, gamma_diff_lb, gamma_diff_ub]\n",
    "\n",
    "    data_gamma = [data_gamma1, data_gammak, data_gamma_diff]\n",
    "    \n",
    "    return data_gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CLAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CLAN(df, controls, k = 5, alpha):\n",
    "    data_CLAN_loop = []\n",
    "    for x in controls: \n",
    "        res_CLAN, t_test = CLAN_single(df, x, k)\n",
    "        data_CLAN = CLAN_to_storage(res_CLAN, t_test, alpha)\n",
    "        data_CLAN_loop.append(data_CLAN)\n",
    "    return data_CLAN_loop\n",
    "\n",
    "def CLAN_single(df, control, k = 5):\n",
    "    '''\n",
    "    Returns the average characteristic for one control between the most and least affected groups \n",
    "    \n",
    "    '''\n",
    "    threshold = 1/k\n",
    "    high_effect = df['S'].quantile(1 - threshold)\n",
    "    low_effect = df['S'].quantile(threshold)\n",
    "    \n",
    "    combined = df.copy()\n",
    "    combined.loc[:,'high'] = (combined.loc[:,\"S\"] > high_effect).astype(int) # dummy variables for high \n",
    "    combined.loc[:,'low'] = (combined.loc[:,\"S\"] > low_effect).astype(int) # dummy variables for low \n",
    "    combined.loc[:,'minusones'] = -1\n",
    "    \n",
    "    X_control = combined[['high', 'low', 'minusones']] # I have no idea why I included minusones \n",
    "    y_control = combined[[control]]\n",
    "    \n",
    "    reg_CLAN = sm.OLS(y_control, X_control)\n",
    "    res_CLAN = reg_CLAN.fit()\n",
    "\n",
    "    hypothesis = \"(high = low)\" \n",
    "    t_test_html = res_CLAN.t_test(hypothesis).summary().as_html()\n",
    "    t_test = pd.read_html(t_test_html, header=0, index_col=0)[0]\n",
    "\n",
    "    res_CLAN = results_summary_to_dataframe(res_CLAN, alpha)\n",
    "    \n",
    "    return res_CLAN, t_test\n",
    "\n",
    "def CLAN_to_storage(res_CLAN, t_test, alpha):\n",
    "    '''\n",
    "    Takes the summary results of CLAN and its t test and store them as lists \n",
    "    '''\n",
    "    h_coeff = res_CLAN.iloc[0,0]\n",
    "    h_se = res_CLAN.iloc[0,1]\n",
    "    h_pvals = res_CLAN.iloc[0,2]\n",
    "    h_lb = res_CLAN.iloc[0,3]\n",
    "    h_ub = res_CLAN.iloc[0,4]\n",
    "    data_h = [h_coeff, h_se, h_pvals, h_lb, h_ub]\n",
    "    \n",
    "    l_coeff = res_CLAN.iloc[1,0]\n",
    "    l_se = res_CLAN.iloc[1,1]\n",
    "    l_pvals = res_CLAN.iloc[1,2]\n",
    "    l_lb = res_CLAN.iloc[1,3]\n",
    "    l_ub = res_CLAN.iloc[1,4]\n",
    "    data_l = [l_coeff, l_se, l_pvals, l_lb, l_ub]\n",
    "    \n",
    "    crit_val = norm.ppf(1-alpha/2) \n",
    "    \n",
    "    diff_coeff = t_test.iloc[0,0]\n",
    "    diff_se = t_test.iloc[0,1]\n",
    "    diff_pvals = t_test.iloc[0,3]\n",
    "    diff_lb = diff_coeff - crit_val * diff_se\n",
    "    diff_ub = diff_coeff + crit_val * diff_se\n",
    "    data_diff = [diff_coeff, diff_se, diff_pvals, diff_lb, diff_ub]\n",
    "    \n",
    "    data_CLAN = data_h, data_l, data_diff\n",
    "    return data_CLAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting data into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_BLP_to_df(data_HET_loop, data_ATE_loop): \n",
    "    '''\n",
    "    Takes the data of BLP stored as a list, find its median over different iterations and adjusts p values. \n",
    "    \n",
    "    Returns it as a dataframe \n",
    "    '''\n",
    "    \n",
    "    data_HET_array = np.array(data_HET_loop)\n",
    "    data_HET_final = np.median(data_HET_array, axis = 0)\n",
    "    data_HET_final[2] = np.minimum(1, data_HET_final[2] *2)\n",
    "\n",
    "    data_ATE_array = np.array(data_ATE_loop)\n",
    "    data_ATE_final = np.median(data_ATE_array, axis = 0)\n",
    "    data_ATE_final[2] = np.minimum(1, data_ATE_final[2] * 2)   \n",
    "    \n",
    "    df_ATE = pd.DataFrame(data_ATE_final, \n",
    "                     index = ['coeff', 'se', 'pvalue', 'lower bound', 'upper bound'], \n",
    "                     columns = ['ATE'])\n",
    "\n",
    "    df_HET = pd.DataFrame(data_HET_final, \n",
    "                     index = ['coeff', 'se', 'pvalue', 'lower bound', 'upper bound'], \n",
    "                     columns = ['HET'])\n",
    "\n",
    "    frames = [df_ATE, df_HET]\n",
    "    \n",
    "    df_BLP = pd.concat(frames, axis = 1)\n",
    "    \n",
    "    return df_BLP\n",
    "    \n",
    "def data_GATES_to_df(data_GATES_loop, groups): \n",
    "    '''\n",
    "    Takes the data of GATES stored as a list, find its median over different iterations and adjusts p values. \n",
    "    \n",
    "    Returns it as a dataframe \n",
    "    '''\n",
    "    \n",
    "    # GATES \n",
    "    data_GATES_array = np.array(data_GATES_loop)\n",
    "    data_GATES_final = np.median(data_GATES_array, axis = 0)\n",
    "    data_GATES_final[:, 2] = np.minimum(1, data_GATES_final[:, 2]* 2)\n",
    "    \n",
    "    df_GATES = pd.DataFrame(data_GATES_final, \n",
    "                        columns = ['coeff', 'se', 'pvalue', 'lower bound', 'upper bound'], \n",
    "                        index = ['G1', \"G\" + str(groups), \"G1 - G\" + str(groups)])\n",
    "    \n",
    "    return df_GATES.transpose()\n",
    "\n",
    "def data_CLAN_to_df(data_CLAN_loop, controls = controls): \n",
    "    '''\n",
    "    Takes the data of GATES stored as a list, find its median over different iterations and adjusts p values. \n",
    "    \n",
    "    Returns it as a dataframe \n",
    "    '''\n",
    "    \n",
    "    # CLAN \n",
    "    data_CLAN_array = np.array(data_CLAN_loop) \n",
    "\n",
    "\n",
    "    data_CLAN_final = np.median(data_CLAN_array, axis = 0) # This code is technically wrong as we take the upper medians for the lower bounds\n",
    "    data_CLAN_final[0,2,:] = np.minimum(1, data_CLAN_final[0,2,:] * 2)\n",
    "    \n",
    "    list = []\n",
    "    for x in controls: \n",
    "        list1 = ['Most affected ' + str(x), 'Least affected ' + str(x), 'Most - least affected ' + str(x) ]\n",
    "        list.append(list1)\n",
    "    \n",
    "    flattened_list = [y for x in list for y in x]\n",
    "\n",
    "    data_CLAN_new = data_CLAN_final.reshape(-1,5)\n",
    "    df_CLAN = pd.DataFrame(data_CLAN_new, \n",
    "                      columns = ['coeff', 'se', 'pvalue', 'lower bound', 'upper bound'], \n",
    "                      index = flattened_list)\n",
    "\n",
    "    return df_CLAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generic_ML_single(df, controls, iterations = 10, model = \"random_forest\", alpha = 0.05, k = 5): \n",
    "    '''\n",
    "    Runs the whole generic ML algorithm for a ML model and returns a list of datasets for all parameters.  \n",
    "    '''\n",
    "    \n",
    "    data_HET_loop = []\n",
    "    data_ATE_loop = []\n",
    "    lambda1_loop = []\n",
    "\n",
    "    data_GATES_loop = []\n",
    "    lambda2_loop = []\n",
    "\n",
    "    data_CLAN_loop = []\n",
    "\n",
    "\n",
    "    for x in range(iterations): \n",
    "        main, aux = sklearn.model_selection.train_test_split(df, train_size = 0.5, random_state = x)\n",
    "        main2 = ML_estimator(main, aux, model) \n",
    "    \n",
    "        # BLP\n",
    "        res_BLP, lambda1 = BLP(main2)\n",
    "        data_HET, data_ATE = BLP_to_storage(res_BLP)\n",
    "        data_HET_loop.append(data_HET)\n",
    "        data_ATE_loop.append(data_ATE)\n",
    "        lambda1_loop.append(lambda1)\n",
    "    \n",
    "        #GATES\n",
    "        res_GATES, t_test_GATES, lambda2 = GATES(main2, k, alpha) \n",
    "        data_GATES = GATES_to_storage(res_GATES, t_test_GATES, alpha)\n",
    "        data_GATES_loop.append(data_GATES)\n",
    "        lambda2_loop.append(lambda2)\n",
    "    \n",
    "        # CLAN\n",
    "        controls = controls \n",
    "        data_CLAN = CLAN(main2, controls)\n",
    "        data_CLAN_loop.append(data_CLAN)\n",
    "\n",
    "        # BLP\n",
    "        data_HET_array = np.array(data_HET_loop)\n",
    "        data_HET_final = np.median(data_HET_array, axis = 0)\n",
    "        data_HET_final[2] = np.minimum(1, data_HET_final[2] *2)\n",
    "\n",
    "        data_ATE_array = np.array(data_ATE_loop)\n",
    "        data_ATE_final = np.median(data_ATE_array, axis = 0)\n",
    "        data_ATE_final[2] = np.minimum(1, data_ATE_final[2] * 2)    \n",
    "    \n",
    "    \n",
    "    df_BLP = data_BLP_to_df(data_HET_loop, data_ATE_loop)\n",
    "    df_GATES = data_GATES_to_df(data_GATES_loop, k)\n",
    "    df_CLAN = data_CLAN_to_df(data_CLAN_loop, controls = controls)\n",
    "    \n",
    "    lambda1 = np.mean(lambda1_loop)\n",
    "    lamda2 = np.mean(lambda2_loop)\n",
    "    \n",
    "    summary = [df_BLP, df_GATES, df_CLAN, lambda1, lambda2]\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ML estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_estimator(main, aux, model):\n",
    "    '''\n",
    "    Returns the main dataset combined with B and S, which are proxy predictors for BCA and CATE respectively \n",
    "    \n",
    "    Parameters \n",
    "    ----------\n",
    "    main: main dataset which must contain treatment and outcome\n",
    "    aux: auxilliary dataset which must contain treatment and outcome\n",
    "    model - in string format \n",
    "        models = [\"random_forest\", \"SVM\", \"gradient_boost\", \"neural_net\", \"ElasticNet\"]\n",
    "    \n",
    "    # need to set the seed of the ML_estimators\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Initialization\n",
    "    aux0 = aux[aux['treatment'] == 0]\n",
    "    aux1 = aux[aux['treatment'] == 1]\n",
    "    X_aux0 = aux0[['treatment', 'X1', 'X2', 'X3', 'X4', 'X5']]\n",
    "    y_aux0 =aux0['outcome']\n",
    "    X_aux1 = aux1[['treatment', 'X1', 'X2', 'X3', 'X4', 'X5']]\n",
    "    y_aux1 =aux1['outcome']\n",
    "    \n",
    "    X_main = main[['treatment', 'X1', 'X2', 'X3', 'X4', 'X5']]\n",
    "    y_main = main['outcome']\n",
    "    \n",
    "    # Model \n",
    "    if model == \"random_forest\": \n",
    "        combined = random_forest(main, X_aux0, y_aux0, X_main, X_aux1, y_aux1)\n",
    "    elif model == \"SVM\": \n",
    "        combined = SVM(main, X_aux0, y_aux0, X_main, X_aux1, y_aux1)\n",
    "    elif model == \"gradient_boost\": \n",
    "        combined = gradient_boost(main, X_aux0, y_aux0, X_main, X_aux1, y_aux1)\n",
    "    elif model == \"neural_net\": \n",
    "        combined = neural_net(main, X_aux0, y_aux0, X_main, X_aux1, y_aux1)\n",
    "    elif model == \"ElasticNet\": \n",
    "        combined = ElasticNet(main, X_aux0, y_aux0, X_main, X_aux1, y_aux1)\n",
    "    \n",
    "    # Add variance\n",
    "    if stats.variance(combined['S']) == 0 : \n",
    "        combined['S'] = combined['S'] + np.random.normal(0,0.1, len(combined['S'])) \n",
    "    if stats.variance(combined['B']) == 0 : \n",
    "        combined['B'] = combined['B'] + np.random.normal(0,0.1, len(combined['B'])) \n",
    "        \n",
    "    return combined\n",
    "\n",
    "def random_forest(main, X_aux0, y_aux0, X_main, X_aux1, y_aux1):\n",
    "    \n",
    "    # Model \n",
    "    clf = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "    \n",
    "    clf.fit(X_aux0, y_aux0)\n",
    "    B = clf.predict(X_main)\n",
    "\n",
    "    clf.fit(X_aux1, y_aux1)\n",
    "    clf.predict(X_main)\n",
    "    S = clf.predict(X_main) - B \n",
    "    \n",
    "    combined = main.copy()\n",
    "    combined['B'] = B \n",
    "    combined['S'] = S\n",
    "        \n",
    "    return combined\n",
    "\n",
    "def SVM(main, X_aux0, y_aux0, X_main, X_aux1, y_aux1):\n",
    "\n",
    "    # Model \n",
    "    clf = svm.SVR()\n",
    "    \n",
    "    clf.fit(X_aux0, y_aux0)\n",
    "    B = clf.predict(X_main)\n",
    "\n",
    "    clf.fit(X_aux1, y_aux1)\n",
    "    clf.predict(X_main)\n",
    "    S = clf.predict(X_main) - B \n",
    "    \n",
    "    combined = main.copy()\n",
    "    combined['B'] = B \n",
    "    combined['S'] = S\n",
    "        \n",
    "    return combined\n",
    "\n",
    "def gradient_boost(main, X_aux0, y_aux0, X_main, X_aux1, y_aux1):\n",
    "\n",
    "    \n",
    "    params = {'n_estimators': 500,\n",
    "          'max_depth': 4,\n",
    "          'min_samples_split': 5,\n",
    "          'learning_rate': 0.01,\n",
    "          'loss': 'ls'}\n",
    "    \n",
    "    # Model \n",
    "    clf = ensemble.GradientBoostingRegressor(**params)\n",
    "    \n",
    "    clf.fit(X_aux0, y_aux0)\n",
    "    B = clf.predict(X_main)\n",
    "\n",
    "    clf.fit(X_aux1, y_aux1)\n",
    "    clf.predict(X_main)\n",
    "    S = clf.predict(X_main) - B \n",
    "    \n",
    "    combined = main.copy()\n",
    "    combined['B'] = B \n",
    "    combined['S'] = S\n",
    "        \n",
    "    return combined\n",
    "\n",
    "def neural_net(main, X_aux0, y_aux0, X_main, X_aux1, y_aux1):\n",
    "    \n",
    "    # Model \n",
    "    clf = MLPRegressor(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "    \n",
    "    clf.fit(X_aux0, y_aux0)\n",
    "    B = clf.predict(X_main)\n",
    "\n",
    "    clf.fit(X_aux1, y_aux1)\n",
    "    clf.predict(X_main)\n",
    "    S = clf.predict(X_main) - B \n",
    "    \n",
    "    combined = main.copy()\n",
    "    combined['B'] = B \n",
    "    combined['S'] = S\n",
    "        \n",
    "    return combined\n",
    "\n",
    "def ElasticNet(main, X_aux0, y_aux0, X_main, X_aux1, y_aux1):\n",
    "        \n",
    "    # Model \n",
    "    clf = sklearn.linear_model.ElasticNet()\n",
    "    \n",
    "    clf.fit(X_aux0, y_aux0)\n",
    "    B = clf.predict(X_main)\n",
    "\n",
    "    clf.fit(X_aux1, y_aux1)\n",
    "    clf.predict(X_main)\n",
    "    S = clf.predict(X_main) - B \n",
    "    \n",
    "    combined = main.copy()\n",
    "    combined['B'] = B \n",
    "    combined['S'] = S\n",
    "        \n",
    "    return combined"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
